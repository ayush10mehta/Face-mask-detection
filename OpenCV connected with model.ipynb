{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"/Users/ayushmehta/Downloads/Projects My/Mask_or_not/drive-download-20210507T111403Z-001/self/final_model.h5\")\n",
    "img_width, img_height= 200,200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('/Users/ayushmehta/Downloads/OpenCV/Harr_face_opencv.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User with Mask 0.9997837\n",
      "User with Mask 0.99958915\n",
      "User with Mask 0.999887\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Taking image from the web cam\n",
    "cap=cv2.VideoCapture(0) #no. for webcam and path for video\n",
    "\n",
    "img_count_full=0\n",
    "#-----------------------------\n",
    "#parameters for text\n",
    "\n",
    "#font\n",
    "font= cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "#org  origin value of text x and y value\n",
    "org=(1,1)\n",
    "\n",
    "class_lable=\" \"   #setting up empty string initially not to show any thing\n",
    "\n",
    "#fonscale\n",
    "fontScale= 0.5 \n",
    "\n",
    "#color\n",
    "color=(0,255,0)\n",
    "\n",
    "#Thickness of line\n",
    "thickness= 1\n",
    "#-----------------------------\n",
    "\n",
    "#Reading images and prediction\n",
    "\n",
    "while True:\n",
    "    img_count_full = img_count_full + 1\n",
    "    \n",
    "    #read image from webcam\n",
    "    responce, color_img = cap.read() #this will give us 2 values \n",
    "                                     #1.response true if we get image and false if not\n",
    "                                     #2.image\n",
    "    #if responce False then break the while loop\n",
    "    if responce == False:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    #resizing the image with 50%  ratio\n",
    "    scale=50\n",
    "    #width=int(color_img[1]* scale/100)\n",
    "    #height=int(color_img[0]* scale/100)\n",
    "    dimension=(200,200)\n",
    "    color_img= cv2.resize(color_img,dimension,interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "    #converting image into gray\n",
    "    gray_img= cv2.cvtColor(color_img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #detecting the face in the image\n",
    "    faces= face_cascade.detectMultiScale(gray_img,1.1,6)\n",
    "    \n",
    "    #take face then predict class masked or not masked then draw rectangle and text then display them\n",
    "    img_count = 0\n",
    "    for (x,y,w,h) in faces:\n",
    "        org= (x-10,y-10) #setting up the location of text\n",
    "        color_face = color_img[y:y+h,x:x+w] #extracting face\n",
    "        #img= load_img(color_face, target_size=(img_width,img_height))   ###\n",
    "        img_count +=1 \n",
    "        cv2.imwrite('/Users/ayushmehta/Downloads/Projects My/Mask_or_not/drive-download-20210507T111403Z-001/self/input/%d%dface.jpg'%(img_count_full,img_count),color_face)\n",
    "        img = load_img('/Users/ayushmehta/Downloads/Projects My/Mask_or_not/drive-download-20210507T111403Z-001/self/input/%d%dface.jpg'%(img_count_full,img_count), target_size=(200,200))\n",
    "        \n",
    "        img=img_to_array(img)/255\n",
    "        img=np.expand_dims(img,axis=0)\n",
    "        pre_model= model.predict(img)  #prediction\n",
    "        prediction= np.argmax(pre_model)\n",
    "        \n",
    "        if prediction==0:\n",
    "            print(\"User with Mask\",pre_model[0][0])\n",
    "            class_lable=\"Mask\"\n",
    "            color=(0,255,0) #color of text\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(\"User without Mask\",pre_model[0][1])\n",
    "            class_lable=\"No Mask\"\n",
    "            color=(0,0,255) #color of text\n",
    "            \n",
    "            \n",
    "        #Drawing rectangle on main image because we know the face coordinates\n",
    "        cv2.rectangle(color_img,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        #add the text\n",
    "        cv2.putText(color_img,class_lable,org,font,fontScale,color,thickness,cv2.LINE_AA)\n",
    "        \n",
    "    \n",
    "    #display imsge\n",
    "    cv2.imshow(\"Live mask detection\",color_img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "#Release the video capture object\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
